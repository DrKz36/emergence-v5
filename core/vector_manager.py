"""
√âMERGENCE V4 - Vector Manager FINAL
ChromaDB clean pour embeddings uniquement
+ Validation k>0 et m√©thodes backend pour interface V4
"""

import chromadb
import logging
import hashlib
import json
import time
from typing import List, Dict, Optional, Any, Tuple
from pathlib import Path
import numpy as np
from sentence_transformers import SentenceTransformer
import threading
from datetime import datetime

# Configuration logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class EmergenceVectorManager:
    """
    Gestionnaire ChromaDB V4 FINAL pour √âMERGENCE
    - Une seule collection 'emergence_vectors'
    - Embeddings optimis√©s avec sentence-transformers
    - Validation k>0 pour √©viter erreurs recherche
    - Sync avec SQLite database
    - Cache embeddings pour performance
    - M√©thodes backend compatibles interface V4
    """
    
    def __init__(self, persist_path: str = "data/vectors", model_name: str = "all-MiniLM-L6-v2"):
        self.persist_path = Path(persist_path)
        # Cr√©er le dossier si n√©cessaire
        self.persist_path.mkdir(parents=True, exist_ok=True)
        
        self.model_name = model_name
        self.lock = threading.RLock()
        
        # Initialisation ChromaDB
        try:
            self.client = chromadb.PersistentClient(path=str(self.persist_path))
            logger.info(f"‚úÖ ChromaDB client initialis√©: {self.persist_path}")
        except Exception as e:
            logger.error(f"‚ùå Erreur init ChromaDB: {e}")
            raise
        
        # Collection unique pour tout √âMERGENCE
        try:
            self.collection = self.client.get_or_create_collection(
                name="emergence_vectors",
                metadata={"hnsw:space": "cosine"}  # Optimisation recherche cosine
            )
            logger.info(f"‚úÖ Collection emergence_vectors pr√™te")
        except Exception as e:
            logger.error(f"‚ùå Erreur collection ChromaDB: {e}")
            raise
        
        # Mod√®le d'embeddings l√©ger et performant
        self._model = None
        self._model_lock = threading.Lock()
        
        # Cache embeddings en m√©moire
        self._embedding_cache = {}
        self._cache_lock = threading.Lock()
        
        # Stats usage
        self._search_count = 0
        self._add_count = 0
        
        logger.info(f"üîÆ √âMERGENCE V4 Vector Manager initialis√©")
        logger.info(f"üìä Collection actuelle : {self.get_collection_count()} vecteurs")
    
    @property
    def model(self) -> SentenceTransformer:
        """Lazy loading du mod√®le d'embeddings (thread-safe)"""
        if self._model is None:
            with self._model_lock:
                if self._model is None:
                    logger.info(f"ü§ñ Chargement mod√®le embeddings : {self.model_name}")
                    try:
                        self._model = SentenceTransformer(self.model_name)
                        logger.info("‚úÖ Mod√®le embeddings charg√©")
                    except Exception as e:
                        logger.error(f"‚ùå Erreur chargement mod√®le: {e}")
                        raise
        return self._model
    
    def get_collection_count(self) -> int:
        """Retourne le nombre de vecteurs dans la collection"""
        try:
            with self.lock:
                return self.collection.count()
        except Exception as e:
            logger.error(f"‚ùå Erreur count collection: {e}")
            return 0
    
    def _generate_embedding_hash(self, text: str) -> str:
        """G√©n√®re un hash unique pour le texte (cache key)"""
        return hashlib.md5(text.encode()).hexdigest()
    
    def _get_cached_embedding(self, text: str) -> Optional[List[float]]:
        """R√©cup√®re embedding depuis le cache m√©moire"""
        cache_key = self._generate_embedding_hash(text)
        with self._cache_lock:
            return self._embedding_cache.get(cache_key)
    
    def _cache_embedding(self, text: str, embedding: List[float]):
        """Met en cache un embedding (limite taille cache)"""
        cache_key = self._generate_embedding_hash(text)
        with self._cache_lock:
            # Limite cache √† 1000 embeddings max
            if len(self._embedding_cache) > 1000:
                # Supprime les plus anciens (FIFO simple)
                oldest_key = next(iter(self._embedding_cache))
                del self._embedding_cache[oldest_key]
            
            self._embedding_cache[cache_key] = embedding
    
    def generate_embedding(self, text: str) -> List[float]:
        """G√©n√®re embedding avec cache intelligent"""
        if not text or not text.strip():
            logger.warning("‚ö†Ô∏è Texte vide pour embedding")
            return [0.0] * 384  # Dimension all-MiniLM-L6-v2
        
        # Check cache d'abord
        cached = self._get_cached_embedding(text)
        if cached is not None:
            return cached
        
        # G√©n√®re nouvel embedding
        try:
            embedding = self.model.encode(text, convert_to_tensor=False).tolist()
            
            # Met en cache
            self._cache_embedding(text, embedding)
            
            return embedding
            
        except Exception as e:
            logger.error(f"‚ùå Erreur g√©n√©ration embedding : {e}")
            # Fallback : embedding z√©ro
            return [0.0] * 384  # Dimension all-MiniLM-L6-v2
    
    def add_text(self, text: str, metadata: Dict[str, Any], doc_id: str = None) -> str:
        """Ajoute un texte avec ses m√©tadonn√©es √† ChromaDB"""
        if not text or not text.strip():
            logger.warning("‚ö†Ô∏è Texte vide ignor√©")
            return None
        
        # G√©n√®re ID unique si pas fourni
        if doc_id is None:
            doc_id = f"doc_{self._generate_embedding_hash(text)}_{int(datetime.now().timestamp())}"
        
        # Pr√©pare m√©tadonn√©es avec timestamp
        full_metadata = {
            "added_at": datetime.now().isoformat(),
            "text_length": len(text),
            "text_hash": self._generate_embedding_hash(text),
            **metadata
        }
        
        try:
            with self.lock:
                # G√©n√®re embedding
                embedding = self.generate_embedding(text)
                
                # Ajoute √† ChromaDB
                self.collection.add(
                    documents=[text],
                    embeddings=[embedding],
                    metadatas=[full_metadata],
                    ids=[doc_id]
                )
                
                self._add_count += 1
                logger.info(f"‚ûï Vecteur ajout√© : {doc_id} ({len(text)} chars)")
                return doc_id
                
        except Exception as e:
            logger.error(f"‚ùå Erreur ajout vecteur : {e}")
            return None
    
    def add_chunks_batch(self, chunks: List[Dict[str, Any]]) -> int:
        """Ajoute plusieurs chunks en batch - Compatible backend V4"""
        added_count = 0
        
        if not chunks:
            logger.warning("‚ö†Ô∏è Liste chunks vide")
            return 0
        
        try:
            with self.lock:
                batch_ids = []
                batch_documents = []
                batch_embeddings = []
                batch_metadatas = []
                
                for chunk in chunks:
                    text = chunk.get('content', '')
                    if not text.strip():
                        continue
                    
                    # ID unique
                    chunk_id = chunk.get('id', f"chunk_{self._generate_embedding_hash(text)}_{int(time.time())}")
                    
                    # M√©tadonn√©es
                    metadata = {
                        "added_at": datetime.now().isoformat(),
                        "text_length": len(text),
                        "chunk_index": chunk.get('chunk_index', 0),
                        "document_id": chunk.get('document_id', ''),
                        "filename": chunk.get('filename', ''),
                        **chunk.get('metadata', {})
                    }
                    
                    # Embedding
                    embedding = self.generate_embedding(text)
                    
                    batch_ids.append(chunk_id)
                    batch_documents.append(text)
                    batch_embeddings.append(embedding)
                    batch_metadatas.append(metadata)
                
                # Ajout batch √† ChromaDB
                if batch_ids:
                    self.collection.add(
                        ids=batch_ids,
                        documents=batch_documents,
                        embeddings=batch_embeddings,
                        metadatas=batch_metadatas
                    )
                    
                    added_count = len(batch_ids)
                    self._add_count += added_count
                    logger.info(f"‚ûï Batch ajout√©: {added_count} vecteurs")
                
        except Exception as e:
            logger.error(f"‚ùå Erreur batch ajout: {e}")
        
        return added_count
    
    def search_similar(self, query: str, k: int = 5, filter_metadata: Dict = None) -> List[Dict]:
        """
        üî• RECHERCHE VECTORIELLE V4 avec VALIDATION k>0
        Compatible avec backend FastAPI
        """
        try:
            # === VALIDATION CRITIQUE k>0 ===
            if k <= 0:
                logger.warning(f"‚ö†Ô∏è Param√®tre k invalide: {k}, utilisation k=5 par d√©faut")
                k = 5
            
            if k > 100:
                logger.warning(f"‚ö†Ô∏è Param√®tre k trop √©lev√©: {k}, limitation √† 20")
                k = 20
            
            # V√©rifier que la collection existe et contient des donn√©es
            collection_count = self.get_collection_count()
            if collection_count == 0:
                logger.warning("‚ö†Ô∏è Collection ChromaDB vide - aucun document index√©")
                return []
            
            # Limiter k au nombre r√©el de documents
            k = min(k, collection_count)
            
            if not query or not query.strip():
                logger.warning("‚ö†Ô∏è Query vide pour recherche vectorielle")
                return []
            
            logger.debug(f"üîç Recherche vectorielle: k={k}, documents={collection_count}, query='{query[:50]}...'")
            
            # G√©n√®re embedding de la requ√™te
            query_embedding = self.generate_embedding(query)
            
            # Pr√©pare filtres ChromaDB
            where_filter = filter_metadata if filter_metadata else None
            
            with self.lock:
                results = self.collection.query(
                    query_embeddings=[query_embedding],
                    n_results=k,
                    where=where_filter,
                    include=["documents", "metadatas", "distances"]
                )
            
            # Formate r√©sultats
            formatted_results = []
            if results and results.get('documents') and results['documents'][0]:
                documents = results['documents'][0]
                metadatas = results.get('metadatas', [[]])[0]
                distances = results.get('distances', [[]])[0]
                ids = results.get('ids', [[]])[0]
                
                for i, doc in enumerate(documents):
                    result = {
                        'id': ids[i] if i < len(ids) else f"unknown_{i}",
                        'content': doc,
                        'metadata': metadatas[i] if i < len(metadatas) else {},
                        'distance': distances[i] if i < len(distances) else 1.0,
                        'similarity': 1 - (distances[i] if i < len(distances) else 1.0),  # Cosine similarity
                        'source': 'vector'
                    }
                    formatted_results.append(result)
            
            self._search_count += 1
            logger.info(f"‚úÖ Recherche vectorielle '{query[:30]}...': {len(formatted_results)} r√©sultats")
            return formatted_results
            
        except Exception as e:
            logger.error(f"‚ùå Erreur recherche vectorielle: {e}")
            return []
    
    def search_by_type(self, query: str, content_type: str, k: int = 10) -> List[Dict]:
        """Recherche par type de contenu (interaction, document, concept)"""
        return self.search_similar(
            query, 
            k, 
            filter_metadata={"type": content_type}
        )
    
    def search_by_document(self, query: str, document_id: str, k: int = 10) -> List[Dict]:
        """Recherche dans un document sp√©cifique"""
        return self.search_similar(
            query,
            k,
            filter_metadata={"document_id": document_id}
        )
    
    def update_vector(self, doc_id: str, new_text: str, new_metadata: Dict = None) -> bool:
        """Met √† jour un vecteur existant"""
        try:
            with self.lock:
                # Supprime ancien vecteur
                self.collection.delete(ids=[doc_id])
                
                # Ajoute nouveau vecteur avec m√™me ID
                if new_metadata:
                    new_metadata["updated_at"] = datetime.now().isoformat()
                
                result = self.add_text(new_text, new_metadata or {}, doc_id)
                return result is not None
                
        except Exception as e:
            logger.error(f"‚ùå Erreur mise √† jour vecteur {doc_id} : {e}")
            return False
    
    def delete_vector(self, doc_id: str) -> bool:
        """Supprime un vecteur"""
        try:
            with self.lock:
                self.collection.delete(ids=[doc_id])
                logger.info(f"üóëÔ∏è Vecteur supprim√© : {doc_id}")
                return True
        except Exception as e:
            logger.error(f"‚ùå Erreur suppression vecteur {doc_id} : {e}")
            return False
    
    def delete_vectors_by_document(self, document_id: str) -> int:
        """Supprime tous les vecteurs d'un document"""
        try:
            with self.lock:
                # Trouve tous les vecteurs du document
                results = self.collection.get(
                    where={"document_id": document_id},
                    include=["metadatas"]
                )
                
                if results and results.get('ids'):
                    ids_to_delete = results['ids']
                    self.collection.delete(ids=ids_to_delete)
                    
                    deleted_count = len(ids_to_delete)
                    logger.info(f"üóëÔ∏è {deleted_count} vecteurs supprim√©s pour document {document_id}")
                    return deleted_count
                else:
                    logger.info(f"‚ÑπÔ∏è Aucun vecteur trouv√© pour document {document_id}")
                    return 0
                    
        except Exception as e:
            logger.error(f"‚ùå Erreur suppression vecteurs document {document_id}: {e}")
            return 0
    
    def get_vector_by_id(self, doc_id: str) -> Optional[Dict]:
        """R√©cup√®re un vecteur par son ID"""
        try:
            with self.lock:
                results = self.collection.get(
                    ids=[doc_id],
                    include=["documents", "metadatas"]
                )
                
                if results and results.get('documents') and results['documents']:
                    return {
                        'id': doc_id,
                        'content': results['documents'][0],
                        'metadata': results['metadatas'][0] if results.get('metadatas') else {}
                    }
                else:
                    return None
                    
        except Exception as e:
            logger.error(f"‚ùå Erreur r√©cup√©ration vecteur {doc_id}: {e}")
            return None
    
    def cleanup_orphaned_vectors(self, valid_document_ids: List[str]) -> int:
        """Nettoie les vecteurs orphelins (documents supprim√©s)"""
        try:
            with self.lock:
                # R√©cup√®re tous les vecteurs avec metadata document_id
                all_vectors = self.collection.get(include=["metadatas"])
                
                to_delete = []
                
                for i, metadata in enumerate(all_vectors.get('metadatas', [])):
                    vector_id = all_vectors['ids'][i]
                    doc_id = metadata.get('document_id')
                    
                    # Si le vecteur a un document_id qui n'est plus valide
                    if doc_id and doc_id not in valid_document_ids:
                        to_delete.append(vector_id)
                
                # Supprime vecteurs orphelins
                if to_delete:
                    self.collection.delete(ids=to_delete)
                    logger.info(f"üßπ Cleanup : {len(to_delete)} vecteurs orphelins supprim√©s")
                
                return len(to_delete)
                
        except Exception as e:
            logger.error(f"‚ùå Erreur cleanup vecteurs : {e}")
            return 0
    
    def get_collection_stats(self) -> Dict:
        """
        üìä Statistiques collection - Compatible backend V4
        """
        try:
            with self.lock:
                total_count = self.get_collection_count()
                
                stats = {
                    "total_vectors": total_count,
                    "cache_size": len(self._embedding_cache),
                    "model": self.model_name,
                    "search_count": self._search_count,
                    "add_count": self._add_count
                }
                
                if total_count == 0:
                    return stats
                
                # R√©cup√®re √©chantillon pour stats d√©taill√©es
                try:
                    sample_size = min(100, total_count)
                    sample = self.collection.get(
                        limit=sample_size,
                        include=["metadatas"]
                    )
                    
                    # Stats par type
                    type_counts = {}
                    document_counts = {}
                    
                    for metadata in sample.get('metadatas', []):
                        # Count par type
                        content_type = metadata.get('type', 'unknown')
                        type_counts[content_type] = type_counts.get(content_type, 0) + 1
                        
                        # Count par document
                        doc_id = metadata.get('document_id', 'unknown')
                        document_counts[doc_id] = document_counts.get(doc_id, 0) + 1
                    
                    stats.update({
                        "types": type_counts,
                        "top_documents": dict(sorted(document_counts.items(), key=lambda x: x[1], reverse=True)[:5])
                    })
                    
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Erreur stats d√©taill√©es: {e}")
                
                return stats
                
        except Exception as e:
            logger.error(f"‚ùå Erreur stats collection : {e}")
            return {"error": str(e)}
    
    def health_check(self) -> Dict[str, Any]:
        """
        üîç Health check syst√®me vectoriel - Compatible backend V4
        """
        health = {
            "status": "healthy",
            "timestamp": datetime.now().isoformat(),
            "checks": {}
        }
        
        try:
            # Test client ChromaDB
            if self.client:
                health["checks"]["client"] = "OK"
            else:
                health["checks"]["client"] = "ERROR: Client non initialis√©"
                health["status"] = "error"
                return health
            
            # Test collection
            try:
                count = self.get_collection_count()
                health["checks"]["collection"] = f"OK ({count} vecteurs)"
            except Exception as e:
                health["checks"]["collection"] = f"ERROR: {e}"
                health["status"] = "degraded"
            
            # Test embeddings
            try:
                test_embedding = self.generate_embedding("test")
                if len(test_embedding) > 0:
                    health["checks"]["embeddings"] = f"OK (dim={len(test_embedding)})"
                else:
                    health["checks"]["embeddings"] = "ERROR: Embeddings vides"
                    health["status"] = "degraded"
            except Exception as e:
                health["checks"]["embeddings"] = f"ERROR: {e}"
                health["status"] = "degraded"
            
            # Test recherche
            try:
                test_results = self.search_similar("test diagnostic", k=1)
                health["checks"]["search"] = f"OK ({len(test_results)} r√©sultats)"
            except Exception as e:
                health["checks"]["search"] = f"ERROR: {e}"
                health["status"] = "degraded"
            
            # Stats
            health["stats"] = self.get_collection_stats()
            
        except Exception as e:
            health["status"] = "error"
            health["error"] = str(e)
            logger.error(f"‚ùå Health check failed: {e}")
        
        return health
    
    def rebuild_collection(self):
        """Reconstruit la collection (en cas de corruption)"""
        try:
            logger.warning("üîÑ Reconstruction collection ChromaDB...")
            
            with self.lock:
                # Sauvegarde donn√©es existantes
                try:
                    backup_data = self.collection.get(include=["documents", "metadatas"])
                except:
                    logger.error("‚ùå Impossible de sauvegarder les donn√©es existantes")
                    backup_data = None
                
                # Supprime collection
                try:
                    self.client.delete_collection("emergence_vectors")
                except:
                    logger.warning("‚ö†Ô∏è Collection d√©j√† supprim√©e ou inexistante")
                
                # Recr√©e collection
                self.collection = self.client.create_collection(
                    name="emergence_vectors",
                    metadata={"hnsw:space": "cosine"}
                )
                
                # Restore donn√©es si possible
                if backup_data and backup_data.get('documents'):
                    restored_count = 0
                    for i, doc in enumerate(backup_data['documents']):
                        try:
                            doc_id = backup_data['ids'][i]
                            metadata = backup_data['metadatas'][i] if i < len(backup_data.get('metadatas', [])) else {}
                            
                            if self.add_text(doc, metadata, doc_id):
                                restored_count += 1
                        except Exception as e:
                            logger.warning(f"‚ö†Ô∏è Erreur restore vecteur {i}: {e}")
                    
                    logger.info(f"‚úÖ Collection reconstruite: {restored_count} vecteurs restaur√©s")
                else:
                    logger.info("‚úÖ Collection reconstruite (vide)")
                
        except Exception as e:
            logger.error(f"‚ùå Erreur reconstruction collection : {e}")
            raise
    
    def clear_cache(self):
        """Vide le cache embeddings"""
        with self._cache_lock:
            cache_size = len(self._embedding_cache)
            self._embedding_cache.clear()
        logger.info(f"üóëÔ∏è Cache embeddings vid√© ({cache_size} entr√©es)")
    
    def reset_stats(self):
        """Remet √† z√©ro les compteurs de stats"""
        self._search_count = 0
        self._add_count = 0
        logger.info("üîÑ Stats usage remises √† z√©ro")

# === INSTANCE GLOBALE ET FACTORY ===

_vector_manager_instance = None

def get_vector_manager() -> EmergenceVectorManager:
    """Factory pour r√©cup√©rer l'instance Vector Manager - Thread-safe"""
    global _vector_manager_instance
    if _vector_manager_instance is None:
        _vector_manager_instance = EmergenceVectorManager()
    return _vector_manager_instance

# Instance par d√©faut
vector_manager = get_vector_manager()

# === TESTS ===
if __name__ == "__main__":
    print("=== TEST √âMERGENCE VECTOR MANAGER V4 ===\n")
    
    # Instance test
    test_vm = EmergenceVectorManager("test_vectors", "all-MiniLM-L6-v2")
    
    # Health check
    health = test_vm.health_check()
    print(f"üìä Health Status: {health['status']}")
    for check, result in health['checks'].items():
        print(f"   {check}: {result}")
    
    # Test ajout texte
    doc_id = test_vm.add_text(
        "Ceci est un test de vecteur pour √âMERGENCE V4", 
        {"type": "test", "document_id": "test123"}
    )
    print(f"\n‚ûï Vecteur ajout√©: {doc_id}")
    
    # Test batch
    chunks = [
        {
            "content": "Premier chunk de test pour batch",
            "document_id": "test123",
            "chunk_index": 0,
            "metadata": {"type": "test"}
        },
        {
            "content": "Second chunk avec validation k>0",
            "document_id": "test123", 
            "chunk_index": 1,
            "metadata": {"type": "test"}
        }
    ]
    batch_count = test_vm.add_chunks_batch(chunks)
    print(f"üì¶ Batch ajout√©: {batch_count} vecteurs")
    
    # Test recherche avec k=0 (validation)
    print(f"\nüîç Test recherche avec k=0 (doit √™tre corrig√©):")
    results_k0 = test_vm.search_similar("test", k=0)
    print(f"   R√©sultats k=0: {len(results_k0)} (devrait √™tre >0)")
    
    # Test recherche normale
    results = test_vm.search_similar("test √âMERGENCE", k=3)
    print(f"\nüîç Recherche 'test √âMERGENCE': {len(results)} r√©sultats")
    for i, result in enumerate(results):
        print(f"   {i+1}. Similarity: {result['similarity']:.3f} - {result['content'][:50]}...")
    
    # Stats finales
    stats = test_vm.get_collection_stats()
    print(f"\nüìà Stats finales:")
    print(f"   Total vecteurs: {stats['total_vectors']}")
    print(f"   Cache size: {stats['cache_size']}")
    print(f"   Recherches: {stats['search_count']}")
    print(f"   Ajouts: {stats['add_count']}")
    
    # Cleanup test
    import shutil
    if Path("test_vectors").exists():
        shutil.rmtree("test_vectors")
    
    print("\n‚úÖ √âMERGENCE VECTOR MANAGER V4 OP√âRATIONNEL")
    print("üéØ CORRECTIONS V4 APPLIQU√âES:")
    print("   ‚úÖ Validation k>0 pour √©viter erreurs recherche")
    print("   ‚úÖ M√©thodes backend compatibles interface V4")
    print("   ‚úÖ Health check complet")
    print("   ‚úÖ Gestion batch chunks")
    print("   ‚úÖ Cache embeddings optimis√©")
    print("   ‚úÖ Stats usage d√©taill√©es")
    print("   ‚úÖ Cleanup et maintenance")
    print("\nüöÄ PR√äT POUR INTERFACE V4 BACKEND")