"""
√âMERGENCE V4 - RAG Manager COMPLET CORRIG√â
Compatible 100% Database V4 + Backend FastAPI
TOUTES les m√©thodes requises par le backend !
"""

import logging
import time
import hashlib
from typing import Dict, List, Optional, Any, Tuple
from datetime import datetime
from pathlib import Path

# Import SEULEMENT database (valid√©)
from .database import get_database

logger = logging.getLogger(__name__)

class RAGManagerV4Minimal:
    """
    RAG Manager V4 COMPLET avec TOUTES les m√©thodes backend
    Compatible 100% Database V4 + FastAPI main.py
    """
    
    def __init__(self):
        self.db = get_database()
        self.initialized = False
        
        try:
            # Test connexion database
            health = self.db.health_check()
            if health['status'] in ['healthy', 'degraded']:
                self.initialized = True
                logger.info(f"‚úÖ RAG Manager V4 COMPLET initialis√© - DB: {health['status']}")
            else:
                logger.error(f"‚ùå Database non disponible: {health}")
        except Exception as e:
            logger.error(f"‚ùå Erreur init RAG: {e}")
    
    def add_document(self, filename: str, file_path: str, content: str = None, 
                    chunks: List[str] = None) -> Tuple[bool, str, Dict]:
        """
        Upload document - Compatible Database V4 API
        """
        if not self.initialized:
            return False, "RAG Manager non initialis√©", {}
        
        start_time = time.time()
        
        try:
            # 1. Hash + taille
            if content:
                file_hash = hashlib.sha256(content.encode('utf-8')).hexdigest()
                file_size = len(content.encode('utf-8'))
            else:
                if not Path(file_path).exists():
                    return False, f"Fichier non trouv√©: {file_path}", {}
                
                with open(file_path, 'rb') as f:
                    file_content = f.read()
                    file_hash = hashlib.sha256(file_content).hexdigest()
                    file_size = len(file_content)
            
            logger.info(f"üìÑ Upload: {filename} ({file_size} bytes)")
            
            # 2. ‚úÖ Database V4: add_document SANS metadata
            try:
                doc_id = self.db.add_document(
                    filename=filename,
                    file_path=file_path, 
                    file_hash=file_hash,
                    file_size=file_size
                )
                logger.info(f"‚úÖ Document en base: {doc_id}")
            except Exception as e:
                logger.error(f"‚ùå add_document failed: {e}")
                return False, f"Erreur DB: {e}", {}
            
            # 3. Chunking simple
            if not chunks and content:
                chunks = self._simple_chunk_content(content)
            elif not chunks:
                chunks = []
            
            # 4. ‚úÖ Database V4: add_chunks format correct
            chunk_count = 0
            if chunks:
                chunks_data = []
                for i, chunk_content in enumerate(chunks):
                    chunks_data.append({
                        'content': chunk_content,
                        'metadata': {
                            'chunk_index': i,
                            'source_file': filename,
                            'created_at': datetime.now().isoformat()
                        }
                    })
                
                try:
                    chunk_count = self.db.add_chunks(doc_id, chunks_data)
                    logger.info(f"‚úÖ {chunk_count} chunks ajout√©s")
                except Exception as e:
                    logger.error(f"‚ùå add_chunks failed: {e}")
            
            processing_time = time.time() - start_time
            
            result = {
                'document_id': doc_id,
                'filename': filename,
                'chunks_added': chunk_count,
                'vectors_added': 0,
                'processing_time': processing_time,
                'status': 'success'
            }
            
            logger.info(f"üéØ Upload r√©ussi: {filename} - {chunk_count} chunks en {processing_time:.2f}s")
            return True, "Document ajout√© avec succ√®s", result
            
        except Exception as e:
            logger.error(f"‚ùå Erreur upload {filename}: {e}")
            return False, f"Erreur: {e}", {}
    
    def _simple_chunk_content(self, content: str, chunk_size: int = 1000) -> List[str]:
        """Chunking simple par taille"""
        if not content or len(content) <= chunk_size:
            return [content] if content else []
        
        chunks = []
        start = 0
        
        while start < len(content):
            end = start + chunk_size
            
            if end < len(content):
                space_pos = content.rfind(' ', start, end)
                if space_pos > start:
                    end = space_pos
            
            chunk = content[start:end].strip()
            if chunk:
                chunks.append(chunk)
            
            start = end
            if start >= len(content):
                break
        
        return chunks
    
    def search(self, query: str, limit: int = 5) -> Tuple[List[Dict], Dict]:
        """
        Recherche FTS5 SQLite
        """
        if not self.initialized:
            return [], {"error": "RAG non initialis√©"}
        
        start_time = time.time()
        
        try:
            # ‚úÖ Database V4: search_chunks
            results = self.db.search_chunks(query, limit=limit)
            
            search_results = []
            for result in results:
                search_results.append({
                    'id': result.get('id'),
                    'content': result.get('content', ''),
                    'filename': result.get('filename', 'unknown'),
                    'document_id': result.get('document_id'),
                    'chunk_index': result.get('chunk_index', 0),
                    'metadata': result.get('metadata', {}),
                    'search_source': result.get('source', 'fts5'),
                    'relevance_score': 0.8
                })
            
            search_stats = {
                'query': query,
                'total_results': len(search_results),
                'processing_time': time.time() - start_time,
                'search_type': 'fts5_only'
            }
            
            logger.info(f"üîç Recherche: {len(search_results)} r√©sultats pour '{query}'")
            return search_results, search_stats
            
        except Exception as e:
            logger.error(f"‚ùå Erreur recherche: {e}")
            return [], {"error": str(e)}
    
    def get_context_for_agent(self, query: str, agent_name: str = "Agent", 
                             max_results: int = 5) -> str:
        """
        Contexte pour agents
        """
        try:
            search_results, stats = self.search(query, limit=max_results)
            
            if not search_results:
                return f"CONTEXTE RAG: Aucun document trouv√© pour '{query[:50]}...'"
            
            context_parts = [
                f"CONTEXTE RAG ({len(search_results)} documents trouv√©s):"
            ]
            
            for i, result in enumerate(search_results, 1):
                filename = result.get('filename', 'Document')
                content = result.get('content', '')[:800]
                
                context_parts.append(f"\n=== DOCUMENT {i}: {filename} ===")
                context_parts.append(content)
                if len(result.get('content', '')) > 800:
                    context_parts.append("... [tronqu√©]")
            
            context_parts.append(f"\nüéØ UTILISE ces {len(search_results)} documents pour r√©pondre pr√©cis√©ment.")
            
            final_context = "\n".join(context_parts)
            
            logger.info(f"üìù Contexte g√©n√©r√© pour {agent_name}: {len(search_results)} docs, {len(final_context)} chars")
            return final_context
            
        except Exception as e:
            logger.error(f"‚ùå Erreur contexte pour {agent_name}: {e}")
            return f"CONTEXTE RAG: Erreur - {str(e)}"
    
    def store_conversation(self, user_msg: str, agent_name: str, response: str, 
                          session_id: str = None, processing_time: float = 0.0,
                          rag_chunks: int = 0) -> bool:
        """
        Store conversation - Database V4
        """
        try:
            conv_id = self.db.store_conversation(
                user_msg=user_msg,
                agent_name=agent_name, 
                response=response,
                session_id=session_id,
                processing_time=processing_time,
                rag_chunks=rag_chunks
            )
            
            logger.info(f"üí¨ Conversation stock√©e: {agent_name}")
            return bool(conv_id)
            
        except Exception as e:
            logger.error(f"‚ùå Erreur store conversation: {e}")
            return False
    
    def get_status(self) -> Dict[str, Any]:
        """
        ‚úÖ AJOUT√â: get_status() pour backend FastAPI
        """
        status = {
            'initialized': self.initialized,
            'timestamp': datetime.now().isoformat()
        }
        
        if self.initialized:
            try:
                health = self.db.health_check()
                status['database'] = health
                
                stats = self.db.get_stats()
                status['stats'] = stats
                
            except Exception as e:
                status['error'] = str(e)
        
        return status
    
    def get_stats(self) -> Dict[str, Any]:
        """
        ‚úÖ AJOUT√â: get_stats() pour backend FastAPI
        """
        try:
            if self.initialized:
                db_stats = self.db.get_stats()
                return {
                    'database': db_stats,
                    'vector_store': {'available': False},
                    'rag_manager': {
                        'initialized': self.initialized,
                        'type': 'minimal_complete'
                    }
                }
            else:
                return {'error': 'RAG Manager non initialis√©'}
        except Exception as e:
            logger.error(f"‚ùå Erreur get_stats: {e}")
            return {'error': str(e)}
    
    def store_document_v4(self, filename: str, content: str, file_path: str = None, 
                         file_hash: str = None, file_size: int = None) -> bool:
        """
        ‚úÖ AJOUT√â: store_document_v4() pour backend FastAPI
        Wrapper vers add_document()
        """
        try:
            success, message, result = self.add_document(
                filename=filename,
                file_path=file_path or f"documents/{filename}",
                content=content
            )
            
            if success:
                logger.info(f"‚úÖ store_document_v4 r√©ussi: {filename}")
                return True
            else:
                logger.error(f"‚ùå store_document_v4 √©chou√©: {message}")
                return False
                
        except Exception as e:
            logger.error(f"‚ùå Erreur store_document_v4: {e}")
            return False
    
    def store_interaction_v4(self, session_id: str, user_message: str, 
                            agent_name: str, agent_response: str, 
                            processing_time: float = None, 
                            rag_chunks_used: int = 0) -> bool:
        """
        ‚úÖ AJOUT√â: store_interaction_v4() pour backend FastAPI  
        Wrapper vers store_conversation()
        """
        try:
            return self.store_conversation(
                user_msg=user_message,
                agent_name=agent_name,
                response=agent_response,
                session_id=session_id,
                processing_time=processing_time or 0.0,
                rag_chunks=rag_chunks_used
            )
        except Exception as e:
            logger.error(f"‚ùå Erreur store_interaction_v4: {e}")
            return False
    
    def hybrid_search(self, query: str, k_docs: int = None, k_interactions: int = None,
                     filename: str = None) -> Dict[str, Any]:
        """
        ‚úÖ AJOUT√â: hybrid_search() pour backend FastAPI
        Version simplifi√©e FTS5 seulement
        """
        try:
            k_docs = k_docs or 5
            search_results, stats = self.search(query, limit=k_docs)
            
            return {
                'results': search_results,
                'search_strategy': 'fts5_only',
                'total_sources': len(search_results),
                'confidence': 0.8 if search_results else 0.0,
                'metadata': {
                    'docs_count': len(search_results),
                    'interactions_count': 0,
                    'query_length': len(query),
                    'has_filename': bool(filename)
                }
            }
        except Exception as e:
            logger.error(f"‚ùå Erreur hybrid_search: {e}")
            return {
                'results': [],
                'search_strategy': 'error',
                'total_sources': 0,
                'confidence': 0.0,
                'metadata': {'error': str(e)}
            }
    
    def get_conversations_context(self, limit: int = 10, session_id: str = None) -> List[Dict]:
        """
        ‚úÖ AJOUT√â: get_conversations_context() pour backend FastAPI
        """
        try:
            if self.initialized:
                conversations = self.db.get_conversations_history(session_id=session_id, limit=limit)
                logger.debug(f"üí¨ Contexte conversations: {len(conversations)} r√©cup√©r√©es")
                return conversations
            else:
                return []
        except Exception as e:
            logger.error(f"‚ùå Erreur get_conversations_context: {e}")
            return []
    
    def cleanup(self):
        """
        ‚úÖ AJOUT√â: cleanup() pour backend FastAPI
        """
        try:
            logger.info("üßπ Cleanup RAG Manager (minimal - rien √† faire)")
        except Exception as e:
            logger.error(f"‚ùå Erreur cleanup: {e}")


# === INSTANCE GLOBALE ===

_rag_instance = None

def get_rag_manager():
    """Factory simple"""
    global _rag_instance
    if _rag_instance is None:
        _rag_instance = RAGManagerV4Minimal()
    return _rag_instance

# Instance par d√©faut
rag_manager = get_rag_manager()


# === TEST ===
if __name__ == "__main__":
    print("=== TEST RAG MANAGER V4 COMPLET CORRIG√â ===")
    
    rag = RAGManagerV4Minimal()
    print(f"Initialis√©: {rag.initialized}")
    
    if rag.initialized:
        # Test get_stats (backend)
        stats = rag.get_stats()
        print(f"Stats: {stats.get('rag_manager', {}).get('type', 'unknown')}")
        
        # Test store_document_v4 (backend)
        success = rag.store_document_v4(
            filename="test_backend.txt",
            content="Test document pour backend FastAPI"
        )
        print(f"store_document_v4: {success}")
        
        if success:
            # Test recherche
            results, search_stats = rag.search("test")
            print(f"Recherche: {len(results)} r√©sultats")
            
            # Test hybrid_search (backend)
            hybrid = rag.hybrid_search("test", k_docs=3)
            print(f"Hybrid search: {hybrid['total_sources']} sources")
            
            # Test contexte
            context = rag.get_context_for_agent("test", "TestAgent")
            print(f"Contexte: {len(context)} chars")
    
    print("\n‚úÖ RAG MANAGER V4 COMPLET - TOUTES M√âTHODES BACKEND INCLUSES !")
    print("üéØ M√âTHODES AJOUT√âES POUR BACKEND:")
    print("   ‚úÖ get_stats()")
    print("   ‚úÖ store_document_v4()")
    print("   ‚úÖ store_interaction_v4()")
    print("   ‚úÖ hybrid_search()")
    print("   ‚úÖ get_conversations_context()")
    print("   ‚úÖ cleanup()")